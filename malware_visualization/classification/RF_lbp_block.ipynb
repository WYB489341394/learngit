{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Summary of the file.\\n    \\n    功能：\\n        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\\n    \\n    输出：\\n        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score,recall_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "''' Summary of the file.\n",
    "    \n",
    "    功能：\n",
    "        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\n",
    "    \n",
    "    输出：\n",
    "        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# # GIST特征值\\nsubfeatures=pd.read_csv(r'E:\\test\\\\process_gist\\\\gist_f_train_full.csv',header=None)\\nlabels = pd.read_csv(r'E:\\test\\\\process_gist\\\\CNO_full.txt',header=None)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实验室的15000条恶意样本，分为十个家族\n",
    "\n",
    "\n",
    "# LBP_block\n",
    "subfeatures=pd.read_csv(r'E:\\test\\process_lpb_block2\\lbp_kmeans_hist_feature.csv',header=None)\n",
    "labels = pd.read_csv(r'E:\\test\\process_lpb_block2\\ClassNo_full.txt',header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把先提取的家族10的特征挪到最后\n",
    "result = pd.concat([subfeatures, labels], axis=1,ignore_index=True)\n",
    "# print(result)\n",
    "result2 = result.iloc[:1431]\n",
    "list = []\n",
    "for i in range(len(result)):\n",
    "    if result.iloc[i,-1] == 10:\n",
    "        list.append(i)\n",
    "result = result.drop(list)\n",
    "result = pd.concat([result,result2],axis=0,ignore_index=True)\n",
    "subfeatures = result.iloc[:,:-1]\n",
    "labels = result.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均准确率归零\n",
    "avgscore = 0\n",
    "recallscore = 0\n",
    "precisionscore = 0\n",
    "N = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "test...\n",
      "0.8722433460076046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.62      0.58       115\n",
      "           2       0.89      0.85      0.87       124\n",
      "           3       0.78      0.71      0.74       103\n",
      "           4       0.83      0.99      0.90       150\n",
      "           5       0.98      0.99      0.98       161\n",
      "           6       1.00      0.99      1.00       158\n",
      "           7       0.84      0.93      0.88       131\n",
      "           8       1.00      0.94      0.97        63\n",
      "           9       0.95      0.74      0.83       164\n",
      "          10       0.93      0.90      0.92       146\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      1315\n",
      "   macro avg       0.87      0.87      0.87      1315\n",
      "weighted avg       0.88      0.87      0.87      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 71   7   7  14   0   0   5   0   3   8]\n",
      " [ 13 105   6   0   0   0   0   0   0   0]\n",
      " [ 14   5  73   3   4   0   2   0   1   1]\n",
      " [  0   0   0 148   0   0   0   0   2   0]\n",
      " [  1   0   1   0 159   0   0   0   0   0]\n",
      " [  1   0   0   0   0 157   0   0   0   0]\n",
      " [  4   0   3   1   0   0 122   0   0   1]\n",
      " [  2   1   1   0   0   0   0  59   0   0]\n",
      " [ 17   0   2   9   0   0  15   0 121   0]\n",
      " [  8   0   0   4   0   0   1   0   1 132]]\n",
      "train...\n",
      "test...\n",
      "0.8935361216730038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.68      0.63       120\n",
      "           2       0.95      0.89      0.92       132\n",
      "           3       0.81      0.76      0.78       122\n",
      "           4       0.89      0.99      0.93       159\n",
      "           5       0.98      0.97      0.98       169\n",
      "           6       1.00      0.99      1.00       140\n",
      "           7       0.92      0.89      0.91       142\n",
      "           8       0.97      1.00      0.98        63\n",
      "           9       0.93      0.83      0.87       143\n",
      "          10       0.92      0.91      0.92       125\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1315\n",
      "   macro avg       0.90      0.89      0.89      1315\n",
      "weighted avg       0.90      0.89      0.89      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 82   3  13   9   0   0   1   0   3   9]\n",
      " [ 10 118   4   0   0   0   0   0   0   0]\n",
      " [ 18   2  93   0   3   0   1   2   2   1]\n",
      " [  1   0   0 157   0   0   0   0   1   0]\n",
      " [  1   0   1   3 164   0   0   0   0   0]\n",
      " [  1   0   0   0   0 139   0   0   0   0]\n",
      " [  7   1   2   3   0   0 127   0   2   0]\n",
      " [  0   0   0   0   0   0   0  63   0   0]\n",
      " [ 11   0   1   4   0   0   9   0 118   0]\n",
      " [  8   0   1   1   0   0   0   0   1 114]]\n",
      "train...\n",
      "test...\n",
      "0.9019011406844106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.73      0.67       111\n",
      "           2       0.96      0.92      0.94       115\n",
      "           3       0.87      0.75      0.81       109\n",
      "           4       0.86      0.99      0.92       156\n",
      "           5       0.98      0.99      0.99       155\n",
      "           6       1.00      0.99      0.99       152\n",
      "           7       0.92      0.92      0.92       153\n",
      "           8       0.96      1.00      0.98        75\n",
      "           9       0.93      0.79      0.86       145\n",
      "          10       0.93      0.89      0.91       144\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1315\n",
      "   macro avg       0.90      0.90      0.90      1315\n",
      "weighted avg       0.91      0.90      0.90      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 81   1   5   8   0   0   2   1   5   8]\n",
      " [  5 106   1   0   0   0   0   2   0   1]\n",
      " [ 11   1  82   7   3   0   1   0   3   1]\n",
      " [  1   0   0 155   0   0   0   0   0   0]\n",
      " [  0   0   0   1 154   0   0   0   0   0]\n",
      " [  2   0   0   0   0 150   0   0   0   0]\n",
      " [  9   0   2   1   0   0 140   0   1   0]\n",
      " [  0   0   0   0   0   0   0  75   0   0]\n",
      " [ 11   1   1   7   0   0  10   0 115   0]\n",
      " [ 11   1   3   1   0   0   0   0   0 128]]\n",
      "train...\n",
      "test...\n",
      "0.8912547528517111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.70      0.66       125\n",
      "           2       0.87      0.92      0.89       130\n",
      "           3       0.88      0.72      0.79       110\n",
      "           4       0.87      0.98      0.92       160\n",
      "           5       0.98      0.99      0.99       162\n",
      "           6       1.00      0.99      1.00       137\n",
      "           7       0.89      0.88      0.89       150\n",
      "           8       0.95      1.00      0.98        79\n",
      "           9       0.94      0.80      0.86       133\n",
      "          10       0.93      0.89      0.91       129\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1315\n",
      "   macro avg       0.89      0.89      0.89      1315\n",
      "weighted avg       0.90      0.89      0.89      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 88   7   6  10   0   0   3   1   4   6]\n",
      " [  6 119   3   0   0   0   0   2   0   0]\n",
      " [ 16   5  79   3   3   0   1   1   0   2]\n",
      " [  2   0   0 157   0   0   0   0   1   0]\n",
      " [  0   0   0   1 161   0   0   0   0   0]\n",
      " [  1   0   0   0   0 136   0   0   0   0]\n",
      " [ 12   3   0   1   0   0 132   0   2   0]\n",
      " [  0   0   0   0   0   0   0  79   0   0]\n",
      " [  5   2   1   7   0   0  12   0 106   0]\n",
      " [ 10   1   1   2   0   0   0   0   0 115]]\n",
      "train...\n",
      "test...\n",
      "0.8790874524714829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.66      0.63       115\n",
      "           2       0.90      0.88      0.89       146\n",
      "           3       0.77      0.68      0.72        97\n",
      "           4       0.80      0.99      0.89       149\n",
      "           5       0.99      0.99      0.99       153\n",
      "           6       1.00      0.99      1.00       142\n",
      "           7       0.92      0.91      0.92       155\n",
      "           8       0.99      0.99      0.99        68\n",
      "           9       0.94      0.72      0.82       160\n",
      "          10       0.89      0.93      0.91       130\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1315\n",
      "   macro avg       0.88      0.87      0.87      1315\n",
      "weighted avg       0.88      0.88      0.88      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 76   7   6  11   0   0   0   1   2  12]\n",
      " [ 10 129   6   1   0   0   0   0   0   0]\n",
      " [ 13   2  66   6   2   0   3   0   4   1]\n",
      " [  1   0   0 148   0   0   0   0   0   0]\n",
      " [  0   0   0   2 151   0   0   0   0   0]\n",
      " [  1   0   0   0   0 141   0   0   0   0]\n",
      " [  6   3   3   1   0   0 141   0   1   0]\n",
      " [  1   0   0   0   0   0   0  67   0   0]\n",
      " [ 15   2   3  14   0   0   8   0 116   2]\n",
      " [  5   0   2   1   0   0   1   0   0 121]]\n",
      "train...\n",
      "test...\n",
      "0.8828897338403042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.63      0.66       126\n",
      "           2       0.88      0.86      0.87       120\n",
      "           3       0.70      0.73      0.71       102\n",
      "           4       0.83      1.00      0.91       149\n",
      "           5       1.00      0.99      0.99       159\n",
      "           6       1.00      0.99      0.99       159\n",
      "           7       0.90      0.90      0.90       145\n",
      "           8       0.99      0.99      0.99        78\n",
      "           9       0.88      0.75      0.81       130\n",
      "          10       0.92      0.92      0.92       147\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1315\n",
      "   macro avg       0.88      0.88      0.88      1315\n",
      "weighted avg       0.88      0.88      0.88      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 80   5  14   7   0   0   6   0   6   8]\n",
      " [  5 103   8   0   0   0   0   1   1   2]\n",
      " [ 12   3  74   7   0   0   1   0   5   0]\n",
      " [  0   0   0 149   0   0   0   0   0   0]\n",
      " [  1   0   0   1 157   0   0   0   0   0]\n",
      " [  1   0   0   0   0 157   0   0   0   1]\n",
      " [  5   2   5   0   0   0 131   0   2   0]\n",
      " [  0   1   0   0   0   0   0  77   0   0]\n",
      " [  6   2   3  12   0   0   8   0  98   1]\n",
      " [  7   1   1   3   0   0   0   0   0 135]]\n",
      "train...\n",
      "test...\n",
      "0.8935361216730038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.66      0.66       121\n",
      "           2       0.88      0.91      0.90       118\n",
      "           3       0.83      0.70      0.76       105\n",
      "           4       0.85      0.99      0.92       165\n",
      "           5       0.95      0.98      0.97       142\n",
      "           6       1.00      0.99      0.99       160\n",
      "           7       0.91      0.88      0.90       137\n",
      "           8       0.98      0.99      0.98        96\n",
      "           9       0.93      0.82      0.87       140\n",
      "          10       0.92      0.93      0.92       131\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1315\n",
      "   macro avg       0.89      0.89      0.89      1315\n",
      "weighted avg       0.89      0.89      0.89      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 80   5   9  13   0   0   2   1   4   7]\n",
      " [ 10 107   0   1   0   0   0   0   0   0]\n",
      " [ 10   5  74   4   6   0   0   1   2   3]\n",
      " [  0   0   0 164   0   0   0   0   1   0]\n",
      " [  1   0   0   2 139   0   0   0   0   0]\n",
      " [  1   0   0   0   1 158   0   0   0   0]\n",
      " [  5   4   4   2   0   0 121   0   0   1]\n",
      " [  0   0   1   0   0   0   0  95   0   0]\n",
      " [  8   0   1   7   0   0   9   0 115   0]\n",
      " [  7   0   0   0   0   0   1   0   1 122]]\n",
      "train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test...\n",
      "0.8912547528517111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.63      0.67       138\n",
      "           2       0.93      0.84      0.89       166\n",
      "           3       0.78      0.82      0.80       101\n",
      "           4       0.86      0.99      0.92       138\n",
      "           5       1.00      0.99      0.99       148\n",
      "           6       1.00      0.98      0.99       131\n",
      "           7       0.88      0.91      0.89       138\n",
      "           8       0.90      1.00      0.95        63\n",
      "           9       0.93      0.86      0.90       145\n",
      "          10       0.87      0.94      0.90       147\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1315\n",
      "   macro avg       0.89      0.90      0.89      1315\n",
      "weighted avg       0.89      0.89      0.89      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 87   2  11   9   0   0   7   2   6  14]\n",
      " [ 16 140   6   0   0   0   1   3   0   0]\n",
      " [  7   3  83   2   0   0   1   2   1   2]\n",
      " [  0   0   0 136   0   0   0   0   2   0]\n",
      " [  0   1   0   1 146   0   0   0   0   0]\n",
      " [  1   0   0   1   0 129   0   0   0   0]\n",
      " [  3   4   5   1   0   0 125   0   0   0]\n",
      " [  0   0   0   0   0   0   0  63   0   0]\n",
      " [  5   0   0   4   0   0   7   0 125   4]\n",
      " [  2   0   2   4   0   0   1   0   0 138]]\n",
      "train...\n",
      "test...\n",
      "0.8980988593155893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.70      0.67       115\n",
      "           2       0.92      0.91      0.92       139\n",
      "           3       0.87      0.77      0.82       112\n",
      "           4       0.82      0.99      0.90       126\n",
      "           5       0.98      0.99      0.99       160\n",
      "           6       1.00      0.99      1.00       144\n",
      "           7       0.94      0.94      0.94       154\n",
      "           8       1.00      0.97      0.99        73\n",
      "           9       0.91      0.79      0.84       155\n",
      "          10       0.91      0.91      0.91       137\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1315\n",
      "   macro avg       0.90      0.90      0.90      1315\n",
      "weighted avg       0.90      0.90      0.90      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 80   6   6  10   0   0   0   0   3  10]\n",
      " [  9 127   3   0   0   0   0   0   0   0]\n",
      " [ 10   2  86   3   2   0   1   0   8   0]\n",
      " [  0   0   0 125   0   0   0   0   1   0]\n",
      " [  1   0   0   0 159   0   0   0   0   0]\n",
      " [  0   0   0   0   1 143   0   0   0   0]\n",
      " [  3   1   2   3   0   0 144   0   0   1]\n",
      " [  1   0   0   0   0   0   1  71   0   0]\n",
      " [ 11   1   1  11   0   0   8   0 122   1]\n",
      " [ 10   1   1   1   0   0   0   0   0 124]]\n",
      "train...\n",
      "test...\n",
      "0.8768060836501901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.69      0.64       124\n",
      "           2       0.87      0.87      0.87       134\n",
      "           3       0.79      0.74      0.76       104\n",
      "           4       0.86      0.99      0.92       153\n",
      "           5       0.98      0.99      0.98       151\n",
      "           6       1.00      0.99      0.99       152\n",
      "           7       0.89      0.86      0.88       148\n",
      "           8       1.00      0.97      0.99        76\n",
      "           9       0.90      0.71      0.79       130\n",
      "          10       0.91      0.92      0.91       143\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1315\n",
      "   macro avg       0.88      0.87      0.87      1315\n",
      "weighted avg       0.88      0.88      0.88      1315\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 85   8   6   8   0   0   2   0   7   8]\n",
      " [ 12 116   5   0   0   0   0   0   1   0]\n",
      " [ 11   3  77   5   3   0   0   0   1   4]\n",
      " [  1   0   0 151   0   0   0   0   1   0]\n",
      " [  1   0   0   1 149   0   0   0   0   0]\n",
      " [  2   0   0   0   0 150   0   0   0   0]\n",
      " [ 12   3   5   0   0   0 128   0   0   0]\n",
      " [  0   2   0   0   0   0   0  74   0   0]\n",
      " [  6   2   5  11   0   0  13   0  92   1]\n",
      " [ 11   0   0   0   0   0   1   0   0 131]]\n"
     ]
    }
   ],
   "source": [
    "# 进行十次随机森林测试\n",
    "for i in range(N):\n",
    "    # 以10%的比例进行交叉验证\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(subfeatures,features_labels,test_size=0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)\n",
    "\n",
    "    # 进行训练\n",
    "    print('train...')\n",
    "    # 进行随机森林训练,30课树，不限制进程数\n",
    "    srf = RF(n_estimators=30, n_jobs=-1)\n",
    "    srf.fit(X_train, y_train)\n",
    "\n",
    "    # 预试\n",
    "    print(\"test...\")\n",
    "    c_test = srf.predict(X_test)\n",
    "\n",
    "\n",
    "    # 计算预测划分准确率\n",
    "    score = srf.score(X_test, y_test)\n",
    "    print(score)\n",
    "    print(classification_report(y_test,c_test))\n",
    "    # print(\"c_test\")\n",
    "    # print(c_test)\n",
    "    # print('y_test')\n",
    "    # print(y_test)\n",
    "\n",
    "    avgscore = avgscore + score\n",
    "    recallscore = recallscore + recall_score(y_test,c_test,average=\"macro\")\n",
    "    precisionscore = precisionscore + precision_score(y_test,c_test,average=\"macro\")\n",
    "    print(\" initial test  labels size\")\n",
    "\n",
    "    # 通过混淆矩阵进行结果标示\n",
    "    cm = confusion_matrix(y_test, c_test)\n",
    "    np.set_printoptions(threshold=10000)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(str(cm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgscore....\n",
      "0.8880608365019012\n",
      "False positive rate\n",
      "0.11197718078396157\n",
      "false negative rate\n",
      "0.11586092345307719\n"
     ]
    }
   ],
   "source": [
    "# 输出N次的平均准确率\n",
    "avgscore = avgscore / N\n",
    "recallscore = recallscore / N\n",
    "precisionscore = precisionscore / N\n",
    "\n",
    "print('avgscore....')\n",
    "print(avgscore)\n",
    "print('False positive rate')\n",
    "print(1-precisionscore)\n",
    "print('false negative rate')\n",
    "print(1-recallscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
