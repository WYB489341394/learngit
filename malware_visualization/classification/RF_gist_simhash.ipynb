{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Summary of the file.\\n    \\n    功能：\\n        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\\n    \\n    输出：\\n        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score,recall_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "''' Summary of the file.\n",
    "    \n",
    "    功能：\n",
    "        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\n",
    "    \n",
    "    输出：\n",
    "        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIST特征值\n",
    "subfeatures = pd.read_csv(r'F:\\virtus_test\\Simhash_Gist\\gist_f_train_full.csv',header=None)\n",
    "labels = pd.read_csv(r'F:\\virtus_test\\Simhash_Gist\\CNO_full.txt',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对全NaN列行进行清除\n",
    "result = pd.concat([subfeatures, labels], axis=1,ignore_index=True)\n",
    "# print(result)\n",
    "result=result.dropna(how='all',axis=1)\n",
    "result=result.dropna(how='any',axis=0)\n",
    "result=result.reindex()\n",
    "# print(result)\n",
    "subfeatures=result.iloc[:,:-1]\n",
    "labels=result.iloc[:,-1]\n",
    "# print(subfeatures,'\\n',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均准确率归零\n",
    "avgscore = 0\n",
    "recallscore = 0\n",
    "precisionscore = 0\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "test...\n",
      "0.9382303839732888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.72      0.76        76\n",
      "           2       0.96      0.96      0.96       143\n",
      "           3       0.86      0.86      0.86        86\n",
      "           4       1.00      1.00      1.00       147\n",
      "           5       1.00      0.89      0.94       162\n",
      "           6       0.89      0.99      0.94       149\n",
      "           7       0.97      0.95      0.96       152\n",
      "           8       0.98      0.98      0.98        46\n",
      "           9       0.90      0.95      0.92       129\n",
      "          10       0.93      0.99      0.96       108\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 55   3   7   0   0   0   1   0   6   4]\n",
      " [  5 137   0   0   0   0   0   1   0   0]\n",
      " [  2   0  74   0   0   0   2   0   5   3]\n",
      " [  0   0   0 147   0   0   0   0   0   0]\n",
      " [  0   0   0   0 144  18   0   0   0   0]\n",
      " [  0   0   1   0   0 148   0   0   0   0]\n",
      " [  2   1   2   0   0   0 145   0   2   0]\n",
      " [  0   1   0   0   0   0   0  45   0   0]\n",
      " [  3   0   2   0   0   0   1   0 122   1]\n",
      " [  1   0   0   0   0   0   0   0   0 107]]\n",
      "train...\n",
      "test...\n",
      "0.9398998330550918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.65      0.73        62\n",
      "           2       0.93      0.98      0.96       145\n",
      "           3       0.83      0.83      0.83        78\n",
      "           4       0.99      1.00      1.00       152\n",
      "           5       1.00      0.90      0.95       156\n",
      "           6       0.91      0.99      0.95       149\n",
      "           7       0.95      0.97      0.96       148\n",
      "           8       0.98      0.98      0.98        51\n",
      "           9       0.93      0.94      0.93       133\n",
      "          10       0.94      0.98      0.96       124\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.92      0.92      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 40   6   6   0   0   0   0   0   5   5]\n",
      " [  0 142   2   0   0   0   0   1   0   0]\n",
      " [  4   1  65   0   0   0   4   0   2   2]\n",
      " [  0   0   0 152   0   0   0   0   0   0]\n",
      " [  0   0   0   0 141  15   0   0   0   0]\n",
      " [  0   0   2   0   0 147   0   0   0   0]\n",
      " [  0   1   1   0   0   0 143   0   3   0]\n",
      " [  0   1   0   0   0   0   0  50   0   0]\n",
      " [  1   1   2   0   0   0   3   0 125   1]\n",
      " [  2   0   0   1   0   0   0   0   0 121]]\n",
      "train...\n",
      "test...\n",
      "0.9407345575959933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.73      0.72        59\n",
      "           2       0.91      0.97      0.94       119\n",
      "           3       0.93      0.84      0.88       105\n",
      "           4       1.00      1.00      1.00       137\n",
      "           5       0.99      0.90      0.94       164\n",
      "           6       0.90      1.00      0.95       131\n",
      "           7       0.95      0.95      0.95       162\n",
      "           8       0.96      1.00      0.98        48\n",
      "           9       0.94      0.94      0.94       140\n",
      "          10       0.99      0.98      0.99       133\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 43   6   4   0   0   0   2   1   3   0]\n",
      " [  2 115   0   0   0   0   1   1   0   0]\n",
      " [ 11   1  88   0   2   0   1   0   1   1]\n",
      " [  0   0   0 137   0   0   0   0   0   0]\n",
      " [  1   0   0   0 148  15   0   0   0   0]\n",
      " [  0   0   0   0   0 131   0   0   0   0]\n",
      " [  1   2   1   0   0   0 154   0   4   0]\n",
      " [  0   0   0   0   0   0   0  48   0   0]\n",
      " [  1   2   1   0   0   0   4   0 132   0]\n",
      " [  1   0   1   0   0   0   0   0   0 131]]\n",
      "train...\n",
      "test...\n",
      "0.9432387312186978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.73      0.77        83\n",
      "           2       0.95      0.97      0.96       149\n",
      "           3       0.87      0.87      0.87        95\n",
      "           4       1.00      0.99      1.00       144\n",
      "           5       0.98      0.93      0.95       135\n",
      "           6       0.94      0.99      0.96       149\n",
      "           7       0.96      0.96      0.96       142\n",
      "           8       0.95      1.00      0.97        37\n",
      "           9       0.93      0.94      0.94       126\n",
      "          10       0.97      0.96      0.96       138\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.94      0.94      0.94      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 61   6   6   0   0   1   2   1   4   2]\n",
      " [  1 144   0   0   0   0   2   1   1   0]\n",
      " [  5   0  83   0   1   0   0   0   4   2]\n",
      " [  0   0   1 143   0   0   0   0   0   0]\n",
      " [  0   0   0   0 126   9   0   0   0   0]\n",
      " [  1   0   0   0   0 148   0   0   0   0]\n",
      " [  1   1   3   0   0   0 137   0   0   0]\n",
      " [  0   0   0   0   0   0   0  37   0   0]\n",
      " [  4   0   1   0   0   0   2   0 119   0]\n",
      " [  3   0   1   0   2   0   0   0   0 132]]\n",
      "train...\n",
      "test...\n",
      "0.9424040066777963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.72      0.69        60\n",
      "           2       0.93      0.93      0.93       124\n",
      "           3       0.94      0.84      0.89       115\n",
      "           4       1.00      1.00      1.00       162\n",
      "           5       0.99      0.96      0.98       146\n",
      "           6       0.96      1.00      0.98       140\n",
      "           7       0.98      0.93      0.95       157\n",
      "           8       0.91      1.00      0.95        41\n",
      "           9       0.92      0.96      0.94       128\n",
      "          10       0.94      0.98      0.96       125\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.92      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 43   6   3   0   0   0   0   0   3   5]\n",
      " [  7 115   1   0   0   0   0   0   1   0]\n",
      " [  6   1  97   0   0   0   2   4   2   3]\n",
      " [  0   0   0 162   0   0   0   0   0   0]\n",
      " [  0   0   0   0 140   6   0   0   0   0]\n",
      " [  0   0   0   0   0 140   0   0   0   0]\n",
      " [  3   2   1   0   1   0 146   0   4   0]\n",
      " [  0   0   0   0   0   0   0  41   0   0]\n",
      " [  3   0   1   0   0   0   1   0 123   0]\n",
      " [  3   0   0   0   0   0   0   0   0 122]]\n",
      "train...\n",
      "test...\n",
      "0.9382303839732888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.83      0.77        70\n",
      "           2       0.97      0.95      0.96       133\n",
      "           3       0.89      0.82      0.85       104\n",
      "           4       0.99      1.00      1.00       153\n",
      "           5       0.99      0.93      0.96       150\n",
      "           6       0.93      0.99      0.96       143\n",
      "           7       0.92      0.94      0.93       143\n",
      "           8       0.92      0.98      0.95        45\n",
      "           9       0.96      0.90      0.93       142\n",
      "          10       0.97      0.99      0.98       115\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 58   4   4   0   0   0   1   1   1   1]\n",
      " [  2 126   1   0   0   0   1   2   1   0]\n",
      " [ 10   0  85   0   0   0   4   1   2   2]\n",
      " [  0   0   0 153   0   0   0   0   0   0]\n",
      " [  0   0   0   0 139  10   0   0   1   0]\n",
      " [  0   0   1   0   0 142   0   0   0   0]\n",
      " [  5   0   2   0   0   0 135   0   1   0]\n",
      " [  0   0   0   0   0   0   1  44   0   0]\n",
      " [  5   0   2   1   1   0   5   0 128   0]\n",
      " [  1   0   0   0   0   0   0   0   0 114]]\n",
      "train...\n",
      "test...\n",
      "0.9348914858096828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.72      0.69        61\n",
      "           2       0.95      0.95      0.95       127\n",
      "           3       0.80      0.78      0.79        86\n",
      "           4       0.99      1.00      0.99       142\n",
      "           5       1.00      0.94      0.97       146\n",
      "           6       0.95      0.99      0.97       157\n",
      "           7       0.95      0.95      0.95       151\n",
      "           8       0.96      0.98      0.97        48\n",
      "           9       0.95      0.93      0.94       152\n",
      "          10       0.96      0.95      0.96       128\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1198\n",
      "   macro avg       0.92      0.92      0.92      1198\n",
      "weighted avg       0.94      0.93      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 44   5   6   1   0   0   1   0   2   2]\n",
      " [  0 121   2   0   0   0   1   2   1   0]\n",
      " [ 11   1  67   0   0   0   4   0   1   2]\n",
      " [  0   0   0 142   0   0   0   0   0   0]\n",
      " [  0   0   1   0 137   8   0   0   0   0]\n",
      " [  1   0   1   0   0 155   0   0   0   0]\n",
      " [  1   1   4   0   0   0 143   0   2   0]\n",
      " [  0   0   0   0   0   0   0  47   1   0]\n",
      " [  5   0   1   1   0   0   2   0 142   1]\n",
      " [  4   0   2   0   0   0   0   0   0 122]]\n",
      "train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test...\n",
      "0.9382303839732888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.72      0.74        79\n",
      "           2       0.92      0.95      0.93       125\n",
      "           3       0.92      0.76      0.83       105\n",
      "           4       0.99      1.00      0.99       160\n",
      "           5       0.98      0.95      0.97       136\n",
      "           6       0.96      0.99      0.97       156\n",
      "           7       0.97      0.96      0.96       138\n",
      "           8       0.91      0.98      0.94        43\n",
      "           9       0.90      0.98      0.94       119\n",
      "          10       0.96      0.97      0.96       137\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 57   8   5   1   1   0   1   0   3   3]\n",
      " [  1 119   0   0   0   0   1   3   1   0]\n",
      " [ 12   2  80   0   0   0   1   1   6   3]\n",
      " [  0   0   0 160   0   0   0   0   0   0]\n",
      " [  0   0   0   0 129   7   0   0   0   0]\n",
      " [  0   0   0   0   1 155   0   0   0   0]\n",
      " [  1   1   2   0   0   0 132   0   2   0]\n",
      " [  0   0   0   0   0   0   0  42   1   0]\n",
      " [  1   0   0   0   0   0   1   0 117   0]\n",
      " [  3   0   0   1   0   0   0   0   0 133]]\n",
      "train...\n",
      "test...\n",
      "0.9382303839732888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.79      0.75        67\n",
      "           2       0.95      0.95      0.95       131\n",
      "           3       0.91      0.82      0.86        95\n",
      "           4       0.99      1.00      1.00       146\n",
      "           5       1.00      0.92      0.96       156\n",
      "           6       0.92      1.00      0.96       133\n",
      "           7       0.97      0.91      0.94       155\n",
      "           8       0.94      1.00      0.97        44\n",
      "           9       0.93      0.96      0.95       135\n",
      "          10       0.94      0.96      0.95       136\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.93      0.93      0.93      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 53   1   3   0   0   0   1   0   4   5]\n",
      " [  1 125   1   0   0   0   0   3   1   0]\n",
      " [ 11   1  78   0   0   0   2   0   0   3]\n",
      " [  0   0   0 146   0   0   0   0   0   0]\n",
      " [  1   0   0   0 143  12   0   0   0   0]\n",
      " [  0   0   0   0   0 133   0   0   0   0]\n",
      " [  5   4   1   0   0   0 141   0   4   0]\n",
      " [  0   0   0   0   0   0   0  44   0   0]\n",
      " [  2   0   2   0   0   0   1   0 130   0]\n",
      " [  2   0   1   1   0   0   0   0   1 131]]\n",
      "train...\n",
      "test...\n",
      "0.9357262103505843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.69      0.70        71\n",
      "           2       0.94      0.97      0.96       134\n",
      "           3       0.84      0.77      0.81        84\n",
      "           4       1.00      1.00      1.00       152\n",
      "           5       0.99      0.93      0.96       154\n",
      "           6       0.93      0.99      0.96       145\n",
      "           7       0.96      0.94      0.95       140\n",
      "           8       1.00      1.00      1.00        45\n",
      "           9       0.90      0.95      0.93       137\n",
      "          10       0.97      0.97      0.97       136\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1198\n",
      "   macro avg       0.92      0.92      0.92      1198\n",
      "weighted avg       0.94      0.94      0.94      1198\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 49   6   9   0   1   0   1   0   3   2]\n",
      " [  1 130   0   0   0   0   0   0   3   0]\n",
      " [ 11   1  65   0   0   0   2   0   3   2]\n",
      " [  0   0   0 152   0   0   0   0   0   0]\n",
      " [  0   0   0   0 143  11   0   0   0   0]\n",
      " [  1   0   1   0   0 143   0   0   0   0]\n",
      " [  1   1   1   0   0   0 132   0   5   0]\n",
      " [  0   0   0   0   0   0   0  45   0   0]\n",
      " [  3   0   0   0   1   0   3   0 130   0]\n",
      " [  3   0   1   0   0   0   0   0   0 132]]\n"
     ]
    }
   ],
   "source": [
    "# 进行十次随机森林测试\n",
    "for i in range(N):\n",
    "    # 以10%的比例进行交叉验证\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(subfeatures,features_labels,test_size=0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)\n",
    "\n",
    "    # 进行训练\n",
    "    print('train...')\n",
    "    # 进行随机森林训练,30课树，不限制进程数\n",
    "    srf = RF(n_estimators=30, n_jobs=-1)\n",
    "    srf.fit(X_train, y_train)\n",
    "\n",
    "    # 预试\n",
    "    print(\"test...\")\n",
    "    c_test = srf.predict(X_test)\n",
    "\n",
    "\n",
    "    # 计算预测划分准确率\n",
    "    score = srf.score(X_test, y_test)\n",
    "    print(score)\n",
    "    print(classification_report(y_test,c_test))\n",
    "    # print(\"c_test\")\n",
    "    # print(c_test)\n",
    "    # print('y_test')\n",
    "    # print(y_test)\n",
    "\n",
    "    avgscore = avgscore + score\n",
    "    recallscore = recallscore + recall_score(y_test,c_test,average=\"macro\")\n",
    "    precisionscore = precisionscore + precision_score(y_test,c_test,average=\"macro\")\n",
    "    print(\" initial test  labels size\")\n",
    "\n",
    "    # 通过混淆矩阵进行结果标示\n",
    "    cm = confusion_matrix(y_test, c_test)\n",
    "    np.set_printoptions(threshold=10000)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(str(cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgscore....\n",
      "0.9389816360601001\n",
      "False positive rate\n",
      "0.0730382907721916\n",
      "false negative rate\n",
      "0.07193824417541106\n"
     ]
    }
   ],
   "source": [
    "# 输出N次的平均准确率\n",
    "avgscore = avgscore / N\n",
    "recallscore = recallscore / N\n",
    "precisionscore = precisionscore / N\n",
    "\n",
    "print('avgscore....')\n",
    "print(avgscore)\n",
    "print('False positive rate')\n",
    "print(1-precisionscore)\n",
    "print('false negative rate')\n",
    "print(1-recallscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
