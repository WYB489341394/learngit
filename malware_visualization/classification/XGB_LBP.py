# -*- coding: utf-8 -*-
"""
Created on Thu Oct 10 15:02:34 2019

@author: WYB48
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn
from sklearn.linear_model import LinearRegression
from scipy import stats
import pylab as pl
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score, precision_score
from sklearn import metrics
import math
from sklearn.datasets.samples_generator import make_blobs
from sklearn.svm import SVC
import xgboost as xgb
from sklearn import datasets

# # LBP特征值
subfeatures=pd.read_csv(r'E:\test\process_lpb\feature_train_full.csv',header=None)
labels = pd.read_csv(r'E:\test\process_lpb\CNO_full.txt',header=None)

# 对全0行进行清除
result = pd.concat([subfeatures, labels], axis=1,ignore_index=True)
'''
print(result)
print(result.apply(lambda x: x.sum(), axis=1))
print(labels.apply(lambda x: x.sum(), axis=1))
print(labels.apply(lambda x: x.sum(), axis=1)==result.apply(lambda x: x.sum(), axis=1))
'''
list=[]
Q = result.apply(lambda x: x.sum(), axis=1)
W = labels.apply(lambda x: x.sum(), axis=1)
for t in range(len(result)):
    if Q[t]==W[t]:
        list.append(t)
#print(list,len(list))  #打印出全零行的标号和个数
result=result.drop(labels=list,axis=0)

subfeatures=result.iloc[:,:-1]
labels=result.iloc[:,-1]

# 平均准确率归零
avgscore = 0
recallscore = 0
precisionscore = 0
N = 10

for i in range(N):
    # 以10%的比例进行交叉验证
    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(subfeatures, features_labels, test_size=0.1)
    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)

    T1 = X_train.values
    T2 = y_train.values.reshape(len(y_train))
    T3 = X_test.values
    T4 = y_test.values.reshape(len(y_test))

    dtrain = xgb.DMatrix(X_train.values, label=y_train.values.reshape(len(y_train)))
    dtest = xgb.DMatrix(X_test.values, label=y_test.values.reshape(len(y_test)))
    classNumber=11
    params = {'booster': 'gbtree',
              'objective': 'multi:softmax',
              'num_class': classNumber,
              'eval_metric': 'auc',
              'max_depth': 6,
              'lambda': 10,
              'subsample': 0.75,
              'colsample_bytree': 0.75,
              'min_child_weight': 2,
              'eta': 0.025,
              'seed': 0,
              'nthread': 8,
              'silent': 1}
    watchlist = [(dtrain, 'train')]

    # 进行训练
    print('train...')
    # 进行SVC训练 使用线性核
    clf = xgb.train(params, dtrain, num_boost_round=100)

    # 预试
    print('test...')
    c_test = clf.predict(dtest)

    # 计算预测划分准确率
    print('accurary...')

    score = accuracy_score(y_test, c_test)
    print(score)

    print(classification_report(y_test, c_test))
    avgscore = avgscore + score
    recallscore = recallscore + recall_score(y_test, c_test, average="macro")
    precisionscore = precisionscore + precision_score(y_test, c_test, average="macro")
    print(score)

    # 通过混淆矩阵进行结果标示
    cm = confusion_matrix(y_test, c_test)
    np.set_printoptions(threshold=10000)
    np.set_printoptions(precision=2)
    print('Confusion matrix, without normalization')
    print(str(cm))

# 输出N次的平均准确率
avgscore = avgscore / N
recallscore = recallscore / N
precisionscore = precisionscore / N

print('avgscore....')
print(avgscore)
print('False positive rate')
print(1-precisionscore)
print('false negative rate')
print(1-recallscore)
