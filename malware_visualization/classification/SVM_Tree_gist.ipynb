{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score\n",
    "import math\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2        3    4    5    6         7    8    9    ...  502  \\\n",
      "0      NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "1      NaN  NaN  NaN  0.23956  NaN  NaN  NaN  0.237630  NaN  NaN  ...  NaN   \n",
      "2      NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "3      NaN  NaN  NaN  0.18744  NaN  NaN  NaN  0.440850  NaN  NaN  ...  NaN   \n",
      "4      NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "5      NaN  NaN  NaN  0.31370  NaN  NaN  NaN  0.401330  NaN  NaN  ...  NaN   \n",
      "6      NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "7      NaN  NaN  NaN  0.33926  NaN  NaN  NaN  0.308770  NaN  NaN  ...  NaN   \n",
      "8      NaN  NaN  NaN  0.32031  NaN  NaN  NaN  0.239320  NaN  NaN  ...  NaN   \n",
      "9      NaN  NaN  NaN  0.16760  NaN  NaN  NaN  0.245140  NaN  NaN  ...  NaN   \n",
      "10     NaN  NaN  NaN  0.25577  NaN  NaN  NaN  0.327910  NaN  NaN  ...  NaN   \n",
      "11     NaN  NaN  NaN  0.40402  NaN  NaN  NaN  0.350880  NaN  NaN  ...  NaN   \n",
      "12     NaN  NaN  NaN  0.26433  NaN  NaN  NaN  0.293290  NaN  NaN  ...  NaN   \n",
      "13     NaN  NaN  NaN  0.40280  NaN  NaN  NaN  0.359690  NaN  NaN  ...  NaN   \n",
      "14     NaN  NaN  NaN  0.27751  NaN  NaN  NaN  0.079934  NaN  NaN  ...  NaN   \n",
      "15     NaN  NaN  NaN  0.31480  NaN  NaN  NaN  0.232990  NaN  NaN  ...  NaN   \n",
      "16     NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "17     NaN  NaN  NaN  0.32580  NaN  NaN  NaN  0.281480  NaN  NaN  ...  NaN   \n",
      "18     NaN  NaN  NaN  0.40505  NaN  NaN  NaN  0.350870  NaN  NaN  ...  NaN   \n",
      "19     NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "20     NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "21     NaN  NaN  NaN  0.34668  NaN  NaN  NaN  0.296430  NaN  NaN  ...  NaN   \n",
      "22     NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "23     NaN  NaN  NaN  0.32627  NaN  NaN  NaN  0.179140  NaN  NaN  ...  NaN   \n",
      "24     NaN  NaN  NaN  0.35351  NaN  NaN  NaN  0.369930  NaN  NaN  ...  NaN   \n",
      "25     NaN  NaN  NaN  0.18990  NaN  NaN  NaN  0.278110  NaN  NaN  ...  NaN   \n",
      "26     NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "27     NaN  NaN  NaN  0.30605  NaN  NaN  NaN  0.205940  NaN  NaN  ...  NaN   \n",
      "28     NaN  NaN  NaN  0.41524  NaN  NaN  NaN  0.285140  NaN  NaN  ...  NaN   \n",
      "29     NaN  NaN  NaN  0.40425  NaN  NaN  NaN  0.350800  NaN  NaN  ...  NaN   \n",
      "...    ...  ...  ...      ...  ...  ...  ...       ...  ...  ...  ...  ...   \n",
      "14535  NaN  NaN  NaN  0.16492  NaN  NaN  NaN  0.313450  NaN  NaN  ...  NaN   \n",
      "14536  NaN  NaN  NaN  0.30400  NaN  NaN  NaN  0.244020  NaN  NaN  ...  NaN   \n",
      "14537  NaN  NaN  NaN  0.33063  NaN  NaN  NaN  0.308390  NaN  NaN  ...  NaN   \n",
      "14538  NaN  NaN  NaN  0.17280  NaN  NaN  NaN  0.361940  NaN  NaN  ...  NaN   \n",
      "14539  NaN  NaN  NaN  0.21129  NaN  NaN  NaN  0.377560  NaN  NaN  ...  NaN   \n",
      "14540  NaN  NaN  NaN  0.36042  NaN  NaN  NaN  0.274140  NaN  NaN  ...  NaN   \n",
      "14541  NaN  NaN  NaN  0.32718  NaN  NaN  NaN  0.264260  NaN  NaN  ...  NaN   \n",
      "14542  NaN  NaN  NaN  0.15066  NaN  NaN  NaN  0.097000  NaN  NaN  ...  NaN   \n",
      "14543  NaN  NaN  NaN  0.25714  NaN  NaN  NaN  0.288890  NaN  NaN  ...  NaN   \n",
      "14544  NaN  NaN  NaN  0.23473  NaN  NaN  NaN  0.317060  NaN  NaN  ...  NaN   \n",
      "14545  NaN  NaN  NaN  0.20726  NaN  NaN  NaN  0.085805  NaN  NaN  ...  NaN   \n",
      "14546  NaN  NaN  NaN  0.19134  NaN  NaN  NaN  0.313740  NaN  NaN  ...  NaN   \n",
      "14547  NaN  NaN  NaN  0.20726  NaN  NaN  NaN  0.085805  NaN  NaN  ...  NaN   \n",
      "14548  NaN  NaN  NaN  0.28021  NaN  NaN  NaN  0.221000  NaN  NaN  ...  NaN   \n",
      "14549  NaN  NaN  NaN  0.22535  NaN  NaN  NaN  0.342270  NaN  NaN  ...  NaN   \n",
      "14550  NaN  NaN  NaN  0.37156  NaN  NaN  NaN  0.282460  NaN  NaN  ...  NaN   \n",
      "14551  NaN  NaN  NaN  0.33058  NaN  NaN  NaN  0.282680  NaN  NaN  ...  NaN   \n",
      "14552  NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "14553  NaN  NaN  NaN  0.23473  NaN  NaN  NaN  0.317060  NaN  NaN  ...  NaN   \n",
      "14554  NaN  NaN  NaN  0.16492  NaN  NaN  NaN  0.313450  NaN  NaN  ...  NaN   \n",
      "14555  NaN  NaN  NaN  0.16492  NaN  NaN  NaN  0.313450  NaN  NaN  ...  NaN   \n",
      "14556  NaN  NaN  NaN      NaN  NaN  NaN  NaN       NaN  NaN  NaN  ...  NaN   \n",
      "14557  NaN  NaN  NaN  0.23473  NaN  NaN  NaN  0.317060  NaN  NaN  ...  NaN   \n",
      "14558  NaN  NaN  NaN  0.25315  NaN  NaN  NaN  0.344990  NaN  NaN  ...  NaN   \n",
      "14559  NaN  NaN  NaN  0.33531  NaN  NaN  NaN  0.236030  NaN  NaN  ...  NaN   \n",
      "14560  NaN  NaN  NaN  0.17280  NaN  NaN  NaN  0.361940  NaN  NaN  ...  NaN   \n",
      "14561  NaN  NaN  NaN  0.26254  NaN  NaN  NaN  0.313660  NaN  NaN  ...  NaN   \n",
      "14562  NaN  NaN  NaN  0.19682  NaN  NaN  NaN  0.316910  NaN  NaN  ...  NaN   \n",
      "14563  NaN  NaN  NaN  0.27122  NaN  NaN  NaN  0.390580  NaN  NaN  ...  NaN   \n",
      "14564  NaN  NaN  NaN  0.22497  NaN  NaN  NaN  0.304430  NaN  NaN  ...  NaN   \n",
      "\n",
      "            503  504  505  506       507  508  509  510       511  \n",
      "0           NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "1      0.009816  NaN  NaN  NaN  0.015357  NaN  NaN  NaN  0.019630  \n",
      "2           NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "3      0.011749  NaN  NaN  NaN  0.010472  NaN  NaN  NaN  0.006301  \n",
      "4           NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "5      0.007033  NaN  NaN  NaN  0.009642  NaN  NaN  NaN  0.009734  \n",
      "6           NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "7      0.006251  NaN  NaN  NaN  0.009986  NaN  NaN  NaN  0.013389  \n",
      "8      0.009204  NaN  NaN  NaN  0.009186  NaN  NaN  NaN  0.010223  \n",
      "9      0.011534  NaN  NaN  NaN  0.014087  NaN  NaN  NaN  0.009006  \n",
      "10     0.006174  NaN  NaN  NaN  0.008846  NaN  NaN  NaN  0.013199  \n",
      "11     0.006966  NaN  NaN  NaN  0.008094  NaN  NaN  NaN  0.005886  \n",
      "12     0.009282  NaN  NaN  NaN  0.014921  NaN  NaN  NaN  0.019272  \n",
      "13     0.009775  NaN  NaN  NaN  0.007487  NaN  NaN  NaN  0.006710  \n",
      "14     0.017264  NaN  NaN  NaN  0.020019  NaN  NaN  NaN  0.022335  \n",
      "15     0.003410  NaN  NaN  NaN  0.003147  NaN  NaN  NaN  0.006102  \n",
      "16          NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "17     0.004694  NaN  NaN  NaN  0.006539  NaN  NaN  NaN  0.004612  \n",
      "18     0.007022  NaN  NaN  NaN  0.008140  NaN  NaN  NaN  0.005941  \n",
      "19          NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "20          NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "21     0.002907  NaN  NaN  NaN  0.002126  NaN  NaN  NaN  0.001415  \n",
      "22          NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "23     0.001530  NaN  NaN  NaN  0.001627  NaN  NaN  NaN  0.002437  \n",
      "24     0.004883  NaN  NaN  NaN  0.004272  NaN  NaN  NaN  0.003273  \n",
      "25     0.002545  NaN  NaN  NaN  0.002350  NaN  NaN  NaN  0.002413  \n",
      "26          NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "27     0.009354  NaN  NaN  NaN  0.009594  NaN  NaN  NaN  0.004724  \n",
      "28     0.006768  NaN  NaN  NaN  0.006692  NaN  NaN  NaN  0.006653  \n",
      "29     0.007001  NaN  NaN  NaN  0.008146  NaN  NaN  NaN  0.005990  \n",
      "...         ...  ...  ...  ...       ...  ...  ...  ...       ...  \n",
      "14535  0.025944  NaN  NaN  NaN  0.023035  NaN  NaN  NaN  0.009718  \n",
      "14536  0.007525  NaN  NaN  NaN  0.006988  NaN  NaN  NaN  0.003355  \n",
      "14537  0.008664  NaN  NaN  NaN  0.009329  NaN  NaN  NaN  0.011800  \n",
      "14538  0.003912  NaN  NaN  NaN  0.003047  NaN  NaN  NaN  0.005045  \n",
      "14539  0.004931  NaN  NaN  NaN  0.003405  NaN  NaN  NaN  0.005217  \n",
      "14540  0.005447  NaN  NaN  NaN  0.002991  NaN  NaN  NaN  0.000897  \n",
      "14541  0.007089  NaN  NaN  NaN  0.007101  NaN  NaN  NaN  0.006179  \n",
      "14542  0.011411  NaN  NaN  NaN  0.008965  NaN  NaN  NaN  0.007252  \n",
      "14543  0.010191  NaN  NaN  NaN  0.005922  NaN  NaN  NaN  0.003317  \n",
      "14544  0.009369  NaN  NaN  NaN  0.012718  NaN  NaN  NaN  0.016172  \n",
      "14545  0.002943  NaN  NaN  NaN  0.005507  NaN  NaN  NaN  0.008767  \n",
      "14546  0.006954  NaN  NaN  NaN  0.006236  NaN  NaN  NaN  0.004737  \n",
      "14547  0.002943  NaN  NaN  NaN  0.005507  NaN  NaN  NaN  0.008767  \n",
      "14548  0.001056  NaN  NaN  NaN  0.005427  NaN  NaN  NaN  0.012139  \n",
      "14549  0.003160  NaN  NaN  NaN  0.003209  NaN  NaN  NaN  0.005590  \n",
      "14550  0.008067  NaN  NaN  NaN  0.011603  NaN  NaN  NaN  0.012520  \n",
      "14551  0.009675  NaN  NaN  NaN  0.009051  NaN  NaN  NaN  0.006705  \n",
      "14552       NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "14553  0.009369  NaN  NaN  NaN  0.012718  NaN  NaN  NaN  0.016172  \n",
      "14554  0.025944  NaN  NaN  NaN  0.023035  NaN  NaN  NaN  0.009718  \n",
      "14555  0.025944  NaN  NaN  NaN  0.023035  NaN  NaN  NaN  0.009718  \n",
      "14556       NaN  NaN  NaN  NaN       NaN  NaN  NaN  NaN       NaN  \n",
      "14557  0.009369  NaN  NaN  NaN  0.012718  NaN  NaN  NaN  0.016172  \n",
      "14558  0.005772  NaN  NaN  NaN  0.007886  NaN  NaN  NaN  0.007716  \n",
      "14559  0.005048  NaN  NaN  NaN  0.007171  NaN  NaN  NaN  0.005794  \n",
      "14560  0.003912  NaN  NaN  NaN  0.003047  NaN  NaN  NaN  0.005045  \n",
      "14561  0.004022  NaN  NaN  NaN  0.002639  NaN  NaN  NaN  0.002332  \n",
      "14562  0.009418  NaN  NaN  NaN  0.009513  NaN  NaN  NaN  0.008276  \n",
      "14563  0.003000  NaN  NaN  NaN  0.002934  NaN  NaN  NaN  0.001393  \n",
      "14564  0.009107  NaN  NaN  NaN  0.008186  NaN  NaN  NaN  0.007373  \n",
      "\n",
      "[14565 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "# GIST特征值\n",
    "subfeatures = pd.read_csv(r'E:\\test\\process_gist2\\gist_f_train_full.csv',header=None)\n",
    "labels = pd.read_csv(r'E:\\test\\process_gist2\\CNO_full.txt',header=None)\n",
    "print(subfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对全NaN列行进行清除\n",
    "result = pd.concat([subfeatures, labels], axis=1,ignore_index=True)\n",
    "# print(result)\n",
    "result=result.dropna(how='all',axis=1)\n",
    "result=result.dropna(how='any',axis=0)\n",
    "result=result.reindex()\n",
    "# print(result)\n",
    "subfeatures=result.iloc[:,:-1]\n",
    "labels=result.iloc[:,-1]\n",
    "# print(subfeatures,'\\n',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均准确率归零\n",
    "avgscore = 0\n",
    "recallscore = 0\n",
    "precisionscore = 0\n",
    "N = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.43      0.48       137\n",
      "           2       0.74      0.86      0.79       121\n",
      "           3       0.71      0.70      0.71       122\n",
      "           4       0.46      0.44      0.45       138\n",
      "           5       0.99      0.99      0.99       141\n",
      "           6       0.97      0.98      0.97        91\n",
      "           7       0.89      0.90      0.90       146\n",
      "           8       0.91      0.97      0.94        70\n",
      "           9       0.76      0.81      0.78       129\n",
      "          10       0.77      0.76      0.77       144\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1239\n",
      "   macro avg       0.77      0.78      0.78      1239\n",
      "weighted avg       0.76      0.77      0.76      1239\n",
      "\n",
      "0.768361581920904\n",
      "Confusion matrix, without normalization\n",
      "[[ 59   8  16  33   0   0   2   2  10   7]\n",
      " [  2 104   1   7   0   0   1   0   2   4]\n",
      " [  7   3  86  10   1   0   3   3   2   7]\n",
      " [ 23  12   7  61   0   0   8   1  14  12]\n",
      " [  0   0   0   1 139   0   0   0   0   1]\n",
      " [  0   0   2   0   0  89   0   0   0   0]\n",
      " [  3   1   1   4   1   1 132   0   3   0]\n",
      " [  0   1   0   1   0   0   0  68   0   0]\n",
      " [  5   6   3   7   0   1   1   0 104   2]\n",
      " [ 10   6   5   8   0   1   1   1   2 110]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.50      0.54       119\n",
      "           2       0.82      0.84      0.83       122\n",
      "           3       0.68      0.66      0.67       101\n",
      "           4       0.55      0.50      0.52       145\n",
      "           5       0.93      1.00      0.96       148\n",
      "           6       0.96      1.00      0.98        79\n",
      "           7       0.90      0.89      0.90       145\n",
      "           8       0.98      0.96      0.97        82\n",
      "           9       0.77      0.75      0.76       154\n",
      "          10       0.74      0.87      0.80       144\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1239\n",
      "   macro avg       0.79      0.80      0.79      1239\n",
      "weighted avg       0.78      0.79      0.78      1239\n",
      "\n",
      "0.7877320419693301\n",
      "Confusion matrix, without normalization\n",
      "[[ 60   6   6  16   4   0   2   0  13  12]\n",
      " [  4 102   2   7   0   0   2   0   3   2]\n",
      " [  7   5  67   8   0   1   2   1   4   6]\n",
      " [ 18   5  18  72   4   2   3   1   9  13]\n",
      " [  0   0   0   0 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0  79   0   0   0   0]\n",
      " [  2   1   2   8   0   0 129   0   1   2]\n",
      " [  0   0   1   1   1   0   0  79   0   0]\n",
      " [  7   3   2  15   1   0   3   0 115   8]\n",
      " [  5   3   0   3   2   0   2   0   4 125]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.39      0.41       119\n",
      "           2       0.84      0.82      0.83       133\n",
      "           3       0.69      0.71      0.70       104\n",
      "           4       0.48      0.44      0.46       154\n",
      "           5       0.95      1.00      0.97       127\n",
      "           6       0.95      0.99      0.97        98\n",
      "           7       0.86      0.92      0.89       128\n",
      "           8       0.96      0.96      0.96        85\n",
      "           9       0.79      0.81      0.80       141\n",
      "          10       0.81      0.79      0.80       150\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1239\n",
      "   macro avg       0.78      0.78      0.78      1239\n",
      "weighted avg       0.76      0.77      0.77      1239\n",
      "\n",
      "0.7699757869249395\n",
      "Confusion matrix, without normalization\n",
      "[[ 47   4   8  34   2   1   5   0   7  11]\n",
      " [  8 109   4   9   0   1   1   0   0   1]\n",
      " [ 11   1  74   8   0   1   2   1   4   2]\n",
      " [ 27  12  11  68   5   2   4   1  15   9]\n",
      " [  0   0   0   0 127   0   0   0   0   0]\n",
      " [  0   0   0   0   0  97   0   0   0   1]\n",
      " [  4   0   0   3   0   0 118   0   2   1]\n",
      " [  0   0   1   1   0   0   0  82   1   0]\n",
      " [  5   1   4  11   0   0   4   0 114   2]\n",
      " [ 10   2   5   9   0   0   3   1   2 118]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.45      0.46       115\n",
      "           2       0.82      0.83      0.82       127\n",
      "           3       0.64      0.76      0.69        95\n",
      "           4       0.57      0.45      0.50       157\n",
      "           5       0.98      0.99      0.98       149\n",
      "           6       0.97      0.98      0.97        87\n",
      "           7       0.88      0.88      0.88       141\n",
      "           8       0.84      0.97      0.90        74\n",
      "           9       0.80      0.76      0.78       138\n",
      "          10       0.76      0.81      0.78       156\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1239\n",
      "   macro avg       0.77      0.79      0.78      1239\n",
      "weighted avg       0.77      0.77      0.77      1239\n",
      "\n",
      "0.7732041969330105\n",
      "Confusion matrix, without normalization\n",
      "[[ 52   5   8  20   2   1   5   3   7  12]\n",
      " [  5 105   2   8   0   0   0   2   1   4]\n",
      " [  4   2  72   5   1   0   5   2   2   2]\n",
      " [ 35   9  12  70   0   0   3   5  12  11]\n",
      " [  0   0   0   1 147   0   0   0   0   1]\n",
      " [  0   0   0   1   0  85   0   0   1   0]\n",
      " [  3   2   2   3   0   0 124   1   2   4]\n",
      " [  0   0   0   2   0   0   0  72   0   0]\n",
      " [  4   3   7   9   0   2   1   1 105   6]\n",
      " [  9   2  10   4   0   0   3   0   2 126]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.43      0.46       109\n",
      "           2       0.85      0.79      0.82       135\n",
      "           3       0.70      0.73      0.71       108\n",
      "           4       0.53      0.49      0.51       142\n",
      "           5       0.98      0.99      0.99       150\n",
      "           6       0.95      0.99      0.97        91\n",
      "           7       0.89      0.89      0.89       143\n",
      "           8       0.92      0.96      0.94        74\n",
      "           9       0.75      0.78      0.77       138\n",
      "          10       0.75      0.84      0.79       149\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1239\n",
      "   macro avg       0.78      0.79      0.79      1239\n",
      "weighted avg       0.78      0.78      0.78      1239\n",
      "\n",
      "0.784503631961259\n",
      "Confusion matrix, without normalization\n",
      "[[ 47   4   8  16   2   1   4   3  12  12]\n",
      " [  9 106   1  14   0   0   0   1   1   3]\n",
      " [  5   3  79   7   0   1   1   1   1  10]\n",
      " [ 18   3  12  70   0   1   6   1  18  13]\n",
      " [  0   0   0   1 149   0   0   0   0   0]\n",
      " [  0   0   0   0   0  90   0   0   1   0]\n",
      " [  2   3   3   7   0   0 127   0   0   1]\n",
      " [  0   1   0   1   0   0   0  71   1   0]\n",
      " [  3   3   5  10   1   2   3   0 108   3]\n",
      " [ 10   1   5   5   0   0   1   0   2 125]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.47      0.46       115\n",
      "           2       0.82      0.82      0.82       115\n",
      "           3       0.67      0.67      0.67       105\n",
      "           4       0.50      0.49      0.49       138\n",
      "           5       0.97      0.99      0.98       154\n",
      "           6       0.95      0.99      0.97        92\n",
      "           7       0.90      0.88      0.89       147\n",
      "           8       0.94      0.94      0.94        69\n",
      "           9       0.85      0.77      0.81       150\n",
      "          10       0.78      0.82      0.80       154\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1239\n",
      "   macro avg       0.78      0.78      0.78      1239\n",
      "weighted avg       0.78      0.78      0.78      1239\n",
      "\n",
      "0.7796610169491526\n",
      "Confusion matrix, without normalization\n",
      "[[ 54   2  10  24   2   0   4   0   7  12]\n",
      " [  5  94   3   3   1   0   2   0   3   4]\n",
      " [ 14   4  70   9   0   0   3   1   2   2]\n",
      " [ 24   6  13  67   1   4   3   0   5  15]\n",
      " [  0   0   0   0 153   0   0   1   0   0]\n",
      " [  0   0   0   0   0  91   0   0   1   0]\n",
      " [  3   1   3   8   0   0 130   0   1   1]\n",
      " [  1   1   1   1   0   0   0  65   0   0]\n",
      " [ 11   1   3  12   0   1   3   1 116   2]\n",
      " [  9   5   2   9   0   0   0   1   2 126]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.37      0.40       133\n",
      "           2       0.81      0.82      0.82       136\n",
      "           3       0.63      0.68      0.66        88\n",
      "           4       0.51      0.47      0.49       148\n",
      "           5       0.96      0.98      0.97       139\n",
      "           6       0.96      0.97      0.96        96\n",
      "           7       0.87      0.86      0.87       151\n",
      "           8       0.89      0.96      0.93        84\n",
      "           9       0.76      0.72      0.74       125\n",
      "          10       0.72      0.84      0.77       139\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1239\n",
      "   macro avg       0.76      0.77      0.76      1239\n",
      "weighted avg       0.75      0.76      0.75      1239\n",
      "\n",
      "0.7570621468926554\n",
      "Confusion matrix, without normalization\n",
      "[[ 49   8  12  27   4   0   4   5  11  13]\n",
      " [  7 112   3   7   0   0   3   0   1   3]\n",
      " [  8   1  60   8   0   0   3   0   3   5]\n",
      " [ 23   9   9  70   1   1   4   1  11  19]\n",
      " [  0   0   1   1 136   0   0   0   0   1]\n",
      " [  1   0   2   0   0  93   0   0   0   0]\n",
      " [  5   1   3   4   0   1 130   2   3   2]\n",
      " [  1   1   0   1   0   0   0  81   0   0]\n",
      " [  8   4   3  11   1   1   3   1  90   3]\n",
      " [  7   2   2   7   0   1   2   1   0 117]]\n",
      "train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.43      0.45       120\n",
      "           2       0.81      0.83      0.82       151\n",
      "           3       0.72      0.76      0.74       111\n",
      "           4       0.54      0.51      0.52       134\n",
      "           5       0.96      0.98      0.97        98\n",
      "           6       0.97      0.98      0.97        92\n",
      "           7       0.84      0.88      0.86       160\n",
      "           8       0.95      0.94      0.95        86\n",
      "           9       0.74      0.71      0.73       140\n",
      "          10       0.80      0.81      0.80       147\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1239\n",
      "   macro avg       0.78      0.78      0.78      1239\n",
      "weighted avg       0.77      0.77      0.77      1239\n",
      "\n",
      "0.7715899919289749\n",
      "Confusion matrix, without normalization\n",
      "[[ 52   7  11  20   0   1   9   0   9  11]\n",
      " [  2 125   3  11   0   0   2   2   2   4]\n",
      " [  7   3  84  10   0   0   3   0   2   2]\n",
      " [ 19   8   8  68   1   0   6   2  16   6]\n",
      " [  1   0   1   0  96   0   0   0   0   0]\n",
      " [  1   1   0   0   0  90   0   0   0   0]\n",
      " [  7   3   2   2   0   1 141   0   1   3]\n",
      " [  0   1   0   0   0   0   2  81   1   1]\n",
      " [ 15   2   6   9   3   1   1   0 100   3]\n",
      " [  8   4   2   6   0   0   4   0   4 119]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.42      0.41       119\n",
      "           2       0.81      0.79      0.80       120\n",
      "           3       0.69      0.69      0.69       102\n",
      "           4       0.54      0.44      0.49       151\n",
      "           5       0.96      1.00      0.98       151\n",
      "           6       0.99      0.99      0.99        89\n",
      "           7       0.82      0.90      0.86       142\n",
      "           8       0.92      0.95      0.94        85\n",
      "           9       0.77      0.76      0.77       142\n",
      "          10       0.77      0.79      0.78       138\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1239\n",
      "   macro avg       0.77      0.77      0.77      1239\n",
      "weighted avg       0.76      0.76      0.76      1239\n",
      "\n",
      "0.7643260694108152\n",
      "Confusion matrix, without normalization\n",
      "[[ 50   4   7  23   3   0  10   2   9  11]\n",
      " [  9  95   1   7   0   0   2   0   4   2]\n",
      " [  9   4  70   9   0   0   2   0   3   5]\n",
      " [ 20  11  14  67   2   1  11   2  14   9]\n",
      " [  0   0   0   0 151   0   0   0   0   0]\n",
      " [  0   0   0   0   0  88   0   0   1   0]\n",
      " [  6   2   1   1   0   0 128   1   0   3]\n",
      " [  0   1   0   1   0   0   1  81   0   1]\n",
      " [ 12   0   4  11   2   0   2   1 108   2]\n",
      " [ 16   1   4   6   0   0   0   1   1 109]]\n",
      "train...\n",
      "test...\n",
      "accurary...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.49      0.53       146\n",
      "           2       0.82      0.80      0.81       118\n",
      "           3       0.65      0.75      0.69        99\n",
      "           4       0.53      0.56      0.55       153\n",
      "           5       0.94      1.00      0.97       137\n",
      "           6       0.99      0.99      0.99        92\n",
      "           7       0.87      0.87      0.87       144\n",
      "           8       0.90      0.93      0.92        75\n",
      "           9       0.87      0.76      0.81       160\n",
      "          10       0.67      0.74      0.71       115\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1239\n",
      "   macro avg       0.78      0.79      0.78      1239\n",
      "weighted avg       0.77      0.77      0.77      1239\n",
      "\n",
      "0.7707828894269573\n",
      "Confusion matrix, without normalization\n",
      "[[ 71   8  11  25   3   0   7   4   7  10]\n",
      " [  5  94   0  12   1   0   2   0   2   2]\n",
      " [  9   1  74  10   0   0   1   0   2   2]\n",
      " [ 15   5  15  86   2   1   4   3   4  18]\n",
      " [  0   0   0   0 137   0   0   0   0   0]\n",
      " [  0   0   0   0   0  91   0   0   0   1]\n",
      " [  8   1   4   3   0   0 125   1   2   0]\n",
      " [  3   1   0   1   0   0   0  70   0   0]\n",
      " [  4   3   6  14   0   0   3   0 122   8]\n",
      " [  8   1   4  11   2   0   2   0   2  85]]\n"
     ]
    }
   ],
   "source": [
    "# 进行十次SVM_Tree测试\n",
    "for i in range(N):\n",
    "    # 以10%的比例进行交叉验证\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(subfeatures, features_labels, test_size=0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)\n",
    "\n",
    "    # 进行训练\n",
    "    print('train...')\n",
    "    # 进行SVC训练 使用线性核\n",
    "    # clf = SVC(kernel='linear')                     # 高斯核 rbf\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train.values, y_train.values.reshape(len(y_train)))\n",
    "\n",
    "    # 预试\n",
    "    print('test...')\n",
    "    c_test = clf.predict(X_test.values)\n",
    "\n",
    "    # print(y_test)\n",
    "    # print(c_test)\n",
    "\n",
    "    # 计算预测划分准确率\n",
    "    print('accurary...')\n",
    "    score = clf.score(X_test.values, y_test.values.reshape(len(y_test)))\n",
    "    print(classification_report(y_test, c_test))\n",
    "    avgscore = avgscore + score\n",
    "    recallscore = recallscore + recall_score(y_test, c_test, average=\"macro\")\n",
    "    precisionscore = precisionscore + precision_score(y_test, c_test, average=\"macro\")\n",
    "    print(score)\n",
    "\n",
    "    # 通过混淆矩阵进行结果标示\n",
    "    cm = confusion_matrix(y_test, c_test)\n",
    "    np.set_printoptions(threshold=10000)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(str(cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgscore....\n",
      "0.7727199354317998\n",
      "False positive rate\n",
      "0.2238523327026083\n",
      "false negative rate\n",
      "0.21616048830988532\n"
     ]
    }
   ],
   "source": [
    "# 输出N次的平均准确率\n",
    "avgscore = avgscore / N\n",
    "recallscore = recallscore / N\n",
    "precisionscore = precisionscore / N\n",
    "\n",
    "print('avgscore....')\n",
    "print(avgscore)\n",
    "print('False positive rate')\n",
    "print(1-precisionscore)\n",
    "print('false negative rate')\n",
    "print(1-recallscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
