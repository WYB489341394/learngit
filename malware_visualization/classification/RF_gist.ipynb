{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Summary of the file.\\n    \\n    功能：\\n        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\\n    \\n    输出：\\n        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score,recall_score\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "''' Summary of the file.\n",
    "    \n",
    "    功能：\n",
    "        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。\n",
    "    \n",
    "    输出：\n",
    "        结果的混淆矩阵，每次划分的准确率，十次的平均准确率\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIST特征值\n",
    "subfeatures = pd.read_csv(r'E:\\test\\process_gist2\\gist_f_train_full.csv',header=None)\n",
    "labels = pd.read_csv(r'E:\\test\\process_gist2\\CNO_full.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对全NaN列行进行清除\n",
    "result = pd.concat([subfeatures, labels], axis=1,ignore_index=True)\n",
    "# print(result)\n",
    "result=result.dropna(how='all',axis=1)\n",
    "result=result.dropna(how='any',axis=0)\n",
    "result=result.reindex()\n",
    "# print(result)\n",
    "subfeatures=result.iloc[:,:-1]\n",
    "labels=result.iloc[:,-1]\n",
    "# print(subfeatures,'\\n',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均准确率归零\n",
    "avgscore = 0\n",
    "recallscore = 0\n",
    "precisionscore = 0\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "test...\n",
      "0.8272800645682001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.60      0.48        99\n",
      "           2       0.98      0.84      0.91       133\n",
      "           3       0.92      0.65      0.76       110\n",
      "           4       0.56      0.82      0.67       153\n",
      "           5       0.99      0.99      0.99       144\n",
      "           6       0.99      0.98      0.98        96\n",
      "           7       0.97      0.84      0.90       147\n",
      "           8       0.97      0.97      0.97        71\n",
      "           9       0.94      0.82      0.87       146\n",
      "          10       0.96      0.79      0.86       140\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1239\n",
      "   macro avg       0.87      0.83      0.84      1239\n",
      "weighted avg       0.87      0.83      0.84      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 59   1   4  32   0   0   0   0   2   1]\n",
      " [  4 112   0  13   0   0   1   2   0   1]\n",
      " [ 17   0  71  20   0   0   0   0   1   1]\n",
      " [ 20   0   1 126   1   0   0   0   4   1]\n",
      " [  0   0   0   2 142   0   0   0   0   0]\n",
      " [  1   0   0   1   0  94   0   0   0   0]\n",
      " [ 11   0   0  11   0   1 123   0   1   0]\n",
      " [  1   0   0   1   0   0   0  69   0   0]\n",
      " [ 13   1   0  10   0   0   2   0 119   1]\n",
      " [ 20   0   1   8   0   0   1   0   0 110]]\n",
      "train...\n",
      "test...\n",
      "0.8159806295399515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.66      0.59       125\n",
      "           2       0.99      0.81      0.89       117\n",
      "           3       0.90      0.65      0.76       110\n",
      "           4       0.52      0.78      0.62       160\n",
      "           5       1.00      1.00      1.00       127\n",
      "           6       0.99      0.99      0.99        87\n",
      "           7       0.99      0.85      0.92       171\n",
      "           8       0.96      0.97      0.97        71\n",
      "           9       0.89      0.73      0.80       146\n",
      "          10       0.88      0.82      0.85       125\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1239\n",
      "   macro avg       0.87      0.83      0.84      1239\n",
      "weighted avg       0.85      0.82      0.83      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 82   0   3  30   0   0   1   1   3   5]\n",
      " [  6  95   0  13   0   0   0   2   1   0]\n",
      " [ 11   0  72  20   0   0   0   0   4   3]\n",
      " [ 27   1   2 125   0   0   0   0   3   2]\n",
      " [  0   0   0   0 127   0   0   0   0   0]\n",
      " [  1   0   0   0   0  86   0   0   0   0]\n",
      " [ 10   0   0  10   0   1 146   0   1   3]\n",
      " [  0   0   0   2   0   0   0  69   0   0]\n",
      " [  9   0   3  26   0   0   0   0 107   1]\n",
      " [  8   0   0  14   0   0   0   0   1 102]]\n",
      "train...\n",
      "test...\n",
      "0.8095238095238095\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.56      0.50       117\n",
      "           2       0.93      0.78      0.85       148\n",
      "           3       0.88      0.65      0.75       116\n",
      "           4       0.52      0.85      0.65       149\n",
      "           5       1.00      1.00      1.00       137\n",
      "           6       1.00      1.00      1.00        75\n",
      "           7       0.99      0.86      0.92       147\n",
      "           8       1.00      0.92      0.96        84\n",
      "           9       0.87      0.74      0.80       136\n",
      "          10       0.91      0.81      0.86       130\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1239\n",
      "   macro avg       0.86      0.82      0.83      1239\n",
      "weighted avg       0.85      0.81      0.82      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 65   3   2  39   0   0   0   0   6   2]\n",
      " [ 11 115   3  19   0   0   0   0   0   0]\n",
      " [ 14   1  75  20   0   0   0   0   4   2]\n",
      " [ 14   2   1 127   0   0   0   0   3   2]\n",
      " [  0   0   0   0 137   0   0   0   0   0]\n",
      " [  0   0   0   0   0  75   0   0   0   0]\n",
      " [ 15   0   0   4   0   0 126   0   1   1]\n",
      " [  0   0   0   7   0   0   0  77   0   0]\n",
      " [ 12   1   2  17   0   0   0   0 101   3]\n",
      " [ 11   1   2   9   0   0   1   0   1 105]]\n",
      "train...\n",
      "test...\n",
      "0.8337368845843423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.62      0.55       116\n",
      "           2       0.98      0.85      0.91       123\n",
      "           3       0.87      0.65      0.74       100\n",
      "           4       0.59      0.84      0.70       148\n",
      "           5       1.00      0.99      1.00       152\n",
      "           6       0.99      1.00      0.99        77\n",
      "           7       0.97      0.88      0.92       144\n",
      "           8       0.94      0.96      0.95        71\n",
      "           9       0.90      0.78      0.83       155\n",
      "          10       0.92      0.81      0.86       153\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1239\n",
      "   macro avg       0.86      0.84      0.85      1239\n",
      "weighted avg       0.86      0.83      0.84      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 72   0   2  31   0   0   1   0   4   6]\n",
      " [ 11 104   1   4   0   0   0   2   1   0]\n",
      " [ 16   0  65  15   0   0   0   2   1   1]\n",
      " [ 14   0   1 125   0   0   1   0   5   2]\n",
      " [  0   0   0   0 151   0   0   0   1   0]\n",
      " [  0   0   0   0   0  77   0   0   0   0]\n",
      " [  5   1   0  10   0   1 126   0   0   1]\n",
      " [  2   0   0   1   0   0   0  68   0   0]\n",
      " [ 13   0   3  15   0   0   2   0 121   1]\n",
      " [ 13   1   3  10   0   0   0   0   2 124]]\n",
      "train...\n",
      "test...\n",
      "0.8272800645682001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.54      0.54       131\n",
      "           2       0.95      0.82      0.88       114\n",
      "           3       0.85      0.68      0.76       104\n",
      "           4       0.55      0.83      0.66       144\n",
      "           5       1.00      0.99      1.00       136\n",
      "           6       0.99      0.99      0.99        95\n",
      "           7       0.98      0.88      0.92       137\n",
      "           8       0.99      0.93      0.96        81\n",
      "           9       0.92      0.80      0.86       147\n",
      "          10       0.85      0.86      0.86       150\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1239\n",
      "   macro avg       0.86      0.83      0.84      1239\n",
      "weighted avg       0.85      0.83      0.83      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 71   2   4  38   0   0   0   1   3  12]\n",
      " [  8  93   2   9   0   0   0   0   1   1]\n",
      " [ 10   2  71  18   0   0   0   0   0   3]\n",
      " [ 17   0   3 119   0   0   0   0   4   1]\n",
      " [  0   0   0   0 135   0   0   0   1   0]\n",
      " [  0   0   1   0   0  94   0   0   0   0]\n",
      " [  4   0   2   6   0   1 120   0   0   4]\n",
      " [  3   1   0   2   0   0   0  75   0   0]\n",
      " [ 11   0   1  13   0   0   3   0 118   1]\n",
      " [  9   0   0  11   0   0   0   0   1 129]]\n",
      "train...\n",
      "test...\n",
      "0.8393866020984665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.70      0.59       119\n",
      "           2       0.97      0.84      0.90       139\n",
      "           3       0.87      0.74      0.80       104\n",
      "           4       0.65      0.85      0.73       170\n",
      "           5       1.00      0.99      1.00       123\n",
      "           6       1.00      0.95      0.98        83\n",
      "           7       0.96      0.85      0.90       133\n",
      "           8       0.99      0.97      0.98        75\n",
      "           9       0.91      0.78      0.84       152\n",
      "          10       0.93      0.81      0.87       141\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1239\n",
      "   macro avg       0.88      0.85      0.86      1239\n",
      "weighted avg       0.87      0.84      0.85      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 83   0   4  25   0   0   0   0   3   4]\n",
      " [ 11 117   2   7   0   0   0   0   1   1]\n",
      " [ 11   1  77  11   0   0   1   1   1   1]\n",
      " [ 18   1   1 144   0   0   2   0   3   1]\n",
      " [  0   0   0   1 122   0   0   0   0   0]\n",
      " [  1   0   1   2   0  79   0   0   0   0]\n",
      " [ 10   0   1   7   0   0 113   0   1   1]\n",
      " [  0   1   0   1   0   0   0  73   0   0]\n",
      " [ 15   1   2  14   0   0   2   0 118   0]\n",
      " [ 13   0   1  10   0   0   0   0   3 114]]\n",
      "train...\n",
      "test...\n",
      "0.7933817594834544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.55      0.51       136\n",
      "           2       0.98      0.84      0.90       142\n",
      "           3       0.79      0.59      0.67       104\n",
      "           4       0.52      0.76      0.62       161\n",
      "           5       1.00      1.00      1.00       129\n",
      "           6       1.00      0.99      0.99        81\n",
      "           7       0.97      0.85      0.91       120\n",
      "           8       0.99      0.97      0.98        68\n",
      "           9       0.84      0.74      0.79       147\n",
      "          10       0.89      0.79      0.84       151\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1239\n",
      "   macro avg       0.84      0.81      0.82      1239\n",
      "weighted avg       0.82      0.79      0.80      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 75   2   5  38   0   0   0   0  10   6]\n",
      " [  5 119   0  16   0   0   0   0   1   1]\n",
      " [ 16   0  61  17   0   0   0   1   4   5]\n",
      " [ 25   0   6 123   0   0   2   0   4   1]\n",
      " [  0   0   0   0 129   0   0   0   0   0]\n",
      " [  0   0   0   1   0  80   0   0   0   0]\n",
      " [  6   0   1   8   0   0 102   0   1   2]\n",
      " [  1   1   0   0   0   0   0  66   0   0]\n",
      " [ 16   0   3  19   0   0   0   0 109   0]\n",
      " [ 14   0   1  16   0   0   1   0   0 119]]\n",
      "train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test...\n",
      "0.807909604519774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.61      0.55       132\n",
      "           2       0.98      0.82      0.90       135\n",
      "           3       0.72      0.68      0.70       101\n",
      "           4       0.56      0.81      0.66       141\n",
      "           5       1.00      0.99      1.00       125\n",
      "           6       1.00      0.95      0.97        92\n",
      "           7       0.99      0.80      0.88       154\n",
      "           8       0.99      1.00      0.99        67\n",
      "           9       0.88      0.78      0.83       146\n",
      "          10       0.84      0.76      0.80       146\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1239\n",
      "   macro avg       0.85      0.82      0.83      1239\n",
      "weighted avg       0.84      0.81      0.82      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 81   1  12  26   0   0   0   1   2   9]\n",
      " [  8 111   2  14   0   0   0   0   0   0]\n",
      " [ 14   0  69   9   0   0   1   0   5   3]\n",
      " [ 19   0   2 114   0   0   0   0   4   2]\n",
      " [  0   0   0   1 124   0   0   0   0   0]\n",
      " [  0   0   2   3   0  87   0   0   0   0]\n",
      " [ 13   0   2  10   0   0 123   0   1   5]\n",
      " [  0   0   0   0   0   0   0  67   0   0]\n",
      " [ 12   0   2  16   0   0   0   0 114   2]\n",
      " [ 14   1   5  12   0   0   0   0   3 111]]\n",
      "train...\n",
      "test...\n",
      "0.8288942695722357\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.58      0.52       114\n",
      "           2       0.98      0.81      0.89       135\n",
      "           3       0.84      0.76      0.80       114\n",
      "           4       0.58      0.81      0.68       161\n",
      "           5       0.99      0.98      0.99       126\n",
      "           6       1.00      0.97      0.98        87\n",
      "           7       0.98      0.87      0.92       140\n",
      "           8       0.98      0.95      0.96        56\n",
      "           9       0.92      0.77      0.84       143\n",
      "          10       0.93      0.87      0.90       163\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1239\n",
      "   macro avg       0.87      0.84      0.85      1239\n",
      "weighted avg       0.86      0.83      0.84      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 66   0   6  34   0   0   0   0   2   6]\n",
      " [  9 110   0  15   0   0   0   0   1   0]\n",
      " [ 11   1  87  10   0   0   1   1   1   2]\n",
      " [ 25   0   4 130   0   0   0   0   2   0]\n",
      " [  0   0   0   2 124   0   0   0   0   0]\n",
      " [  0   0   1   2   0  84   0   0   0   0]\n",
      " [  8   0   3   5   0   0 122   0   0   2]\n",
      " [  3   0   0   0   0   0   0  53   0   0]\n",
      " [ 14   0   2  15   0   0   1   0 110   1]\n",
      " [  6   1   1  10   1   0   0   0   3 141]]\n",
      "train...\n",
      "test...\n",
      "0.8151735270379338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.58      0.55       124\n",
      "           2       0.99      0.81      0.89       144\n",
      "           3       0.84      0.69      0.76       103\n",
      "           4       0.52      0.77      0.62       158\n",
      "           5       1.00      0.99      0.99       137\n",
      "           6       1.00      0.98      0.99       101\n",
      "           7       0.94      0.89      0.92       131\n",
      "           8       0.97      1.00      0.98        65\n",
      "           9       0.87      0.78      0.82       158\n",
      "          10       0.89      0.76      0.82       118\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1239\n",
      "   macro avg       0.85      0.82      0.83      1239\n",
      "weighted avg       0.84      0.82      0.82      1239\n",
      "\n",
      " initial test  labels size\n",
      "Confusion matrix, without normalization\n",
      "[[ 72   0   5  33   0   0   2   0   9   3]\n",
      " [  7 117   2  15   0   0   0   1   1   1]\n",
      " [  9   1  71  15   0   0   1   0   4   2]\n",
      " [ 26   0   2 121   0   0   0   1   4   4]\n",
      " [  0   0   1   1 135   0   0   0   0   0]\n",
      " [  1   0   1   0   0  99   0   0   0   0]\n",
      " [  2   0   0  10   0   0 117   0   1   1]\n",
      " [  0   0   0   0   0   0   0  65   0   0]\n",
      " [  8   0   0  24   0   0   3   0 123   0]\n",
      " [ 11   0   3  13   0   0   1   0   0  90]]\n"
     ]
    }
   ],
   "source": [
    "# 进行十次随机森林测试\n",
    "for i in range(N):\n",
    "    # 以10%的比例进行交叉验证\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(subfeatures,features_labels,test_size=0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)\n",
    "\n",
    "    # 进行训练\n",
    "    print('train...')\n",
    "    # 进行随机森林训练,30课树，不限制进程数\n",
    "    srf = RF(n_estimators=30, n_jobs=-1)\n",
    "    srf.fit(X_train, y_train)\n",
    "\n",
    "    # 预试\n",
    "    print(\"test...\")\n",
    "    c_test = srf.predict(X_test)\n",
    "\n",
    "\n",
    "    # 计算预测划分准确率\n",
    "    score = srf.score(X_test, y_test)\n",
    "    print(score)\n",
    "    print(classification_report(y_test,c_test))\n",
    "    # print(\"c_test\")\n",
    "    # print(c_test)\n",
    "    # print('y_test')\n",
    "    # print(y_test)\n",
    "\n",
    "    avgscore = avgscore + score\n",
    "    recallscore = recallscore + recall_score(y_test,c_test,average=\"macro\")\n",
    "    precisionscore = precisionscore + precision_score(y_test,c_test,average=\"macro\")\n",
    "    print(\" initial test  labels size\")\n",
    "\n",
    "    # 通过混淆矩阵进行结果标示\n",
    "    cm = confusion_matrix(y_test, c_test)\n",
    "    np.set_printoptions(threshold=10000)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(str(cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avgscore....\n",
      "0.8198547215496367\n",
      "False positive rate\n",
      "0.13912149620781522\n",
      "false negative rate\n",
      "0.17229023701977053\n"
     ]
    }
   ],
   "source": [
    "# 输出N次的平均准确率\n",
    "avgscore = avgscore / N\n",
    "recallscore = recallscore / N\n",
    "precisionscore = precisionscore / N\n",
    "\n",
    "print('avgscore....')\n",
    "print(avgscore)\n",
    "print('False positive rate')\n",
    "print(1-precisionscore)\n",
    "print('false negative rate')\n",
    "print(1-recallscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
