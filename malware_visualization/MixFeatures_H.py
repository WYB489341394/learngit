from sklearn.ensemble import RandomForestClassifier as RF
from sklearn import cross_validation
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from collections import Counter
import pandas as pd
import numpy as np

''' Summary of the file.

    功能：
        实现特征的混合分类方法：
        构造的公式是对随机森林分类后概率矩阵的相加比例：
            proba = proba1*(P) + proba2*(1-P)
        上面，proba1是由GIST特征算出来的分类概率矩阵，proba2是由lbp或dense sift算出来的分类概率矩阵。
        这个权重P是一个不确定的值，不同的混合方法会有不同的最优值。
        最后根据合成的这个概率矩阵proba获得每个样本的分类情况

        读取特征值文件和标签文件，通过交叉验证获得训练集和测试集，以随机森林方法划分并获得准确率，通过混淆矩阵标示结果。

    输出：
        结果的混淆矩阵，每次划分的准确率，N次的平均准确率
'''



# # 读取两组数据，每组数据含有两种特征。每组数据进行混合分类

# # Test 1 (Gist + lbp)
# # GIST特征值
# subfeatures = pd.read_csv('/usr/local/MATLAB/Data/Gist_feature/gist_f_train_full.csv',header=None)
# labels = pd.read_csv('/usr/local/MATLAB/Data/Gist_feature/CNO_full.txt',header=None)
# # LBP特征值
# subfeatures2 = pd.read_csv('/usr/local/MATLAB/Data/lbp_only_features/feature_train_full.csv',header=None)
# labels2 = pd.read_csv('/usr/local/MATLAB/Data/lbp_only_features/CNO_full.txt',header=None)

# # Test 2 (Gist + dense sift)
# # GIST特征值
# subfeatures = pd.read_csv('/usr/local/MATLAB/Data/Gist_feature/gist_f_train_full.csv', header=None)
# labels = pd.read_csv('/usr/local/MATLAB/Data/Gist_feature/CNO_full.txt', header=None)
# # Dense sift Kmeans100 CenterHist
# subfeaturesTemp = pd.read_csv('/usr/local/MATLAB/Data/dense_sift_Kmeans100_hist100/dense_sift_hist100_full.csv',
#                               header=None)
# labelsTemp = pd.read_csv('/usr/local/MATLAB/Data/dense_sift_Kmeans100_hist100/dense_sift_ClassNo_full.csv', header=None)
# # 由于dense sift的特征在文件中的编号方法为字典排序，不是数值排序，这里先进行排序的重置。
# subfeaturesTemp[-1] = labelsTemp[0]
# subfeatures2 = subfeaturesTemp.sort_values([-1], ascending=True).ix[:, 0:99]
# labels2 = subfeaturesTemp.sort_values([-1], ascending=True)[-1]
# subfeatures2.index = range(len(subfeatures2))
# labels2.index = range(len(labels2))

# # Test 3 (Gist + lbp) 新的数据集
# # GIST特征值
# subfeatures = pd.read_csv('/usr/local/MATLAB/Data/Gist_Only_New/gist_f_train_full.csv',header=None)
# labels = pd.read_csv('/usr/local/MATLAB/Data/Gist_Only_New/CNO_full.txt',header=None)
# # LBP特征值
# subfeatures2 = pd.read_csv('/usr/local/MATLAB/Data/Lbp_Only_New/feature_train_full.csv',header=None)
# labels2 = pd.read_csv('/usr/local/MATLAB/Data/Lbp_Only_New/CNO_full.txt',header=None)

# # Test 4 (Gist + dense sift) 新的数据集
# GIST特征值
subfeatures = pd.read_csv('/usr/local/MATLAB/Data/Gist_Only_New/gist_f_train_full.csv',header=None)
labels = pd.read_csv('/usr/local/MATLAB/Data/Gist_Only_New/CNO_full.txt',header=None)
# Dense sift Kmeans100 CenterHist
subfeaturesTemp = pd.read_csv('/usr/local/MATLAB/Data/dense_sift_Kmeans100/dense_sift_hist100_full.csv',header=None)
labelsTemp = pd.read_csv('/usr/local/MATLAB/Data/dense_sift_Kmeans100/dense_sift_ClassNo_full.csv',header=None)
# 由于dense sift的特征在文件中的编号方法为字典排序，不是数值排序，这里先进行排序的重置。
subfeaturesTemp[-1] = labelsTemp[0]
subfeatures2 = subfeaturesTemp.sort_values([-1],ascending=True).ix[:,0:99]
labels2 = subfeaturesTemp.sort_values([-1],ascending=True)[-1]
subfeatures2.index = range(len(subfeatures2))
labels2.index = range(len(labels2))

# 合并两条特征
subfeatures2.columns = range(len(subfeatures.columns),len(subfeatures.columns)+len(subfeatures2.columns))
subfeatures[-1] = subfeatures.index;
subfeatures2[-1] = subfeatures2.index;
subfeatures = pd.merge(subfeatures,subfeatures2,on=-1)
subfeatures = subfeatures.drop(-1,axis=1)

# print("New subfeatures")
# print(subfeatures)


# 临时修改标签(不变序的数据)
# m = [5,8]       # 旧数据集的家族更改方案
m = [11,12,30,31]       # 新数据集的家族更改方案
first = 0
N = 0

for i in range(len(labels)):
    if(labels[0].get(i) in m) and (labels[0].get(i) != first):
        N = N + 1;
        first = labels[0].get(i)
    labels.ix[i] = labels.ix[i] - N;

# 平均准确率归零 实验次数
avgscore = 0
N = 30

# 进行N次随机森林测试
for i in range(N):
    # 以10%的比例进行交叉验证
    X_train, X_test, y_train, y_test = train_test_split(subfeatures, labels, test_size=0.1)
    print("ROUND:", i)
    print("train")

    # 合并两条相对应的特征


    # 进行训练
    print('train...')
    # 进行随机森林训练,30课树，不限制进程数，为两个混合的特征集各自产生一个随机森林
    srf = RF(n_estimators=30, n_jobs=-1)
    srf.fit(X_train, y_train)


    # 预试
    print("test...")
    c_test = srf.predict(X_test)

    # 计算预测划分准确率
    score = srf.score(X_test, y_test)
    print(score)

    # 累加分数
    avgscore = avgscore + score
    print(" initial test  labels size")

    # 通过混淆矩阵进行结果标示
    cm = confusion_matrix(y_test, c_test)
    np.set_printoptions(threshold=np.nan)
    np.set_printoptions(precision=2)
    print('Confusion matrix, without normalization')
    print(str(cm))

# 输出十次的平均准确率
avgscore = avgscore / N
print('avgscore....')
print(avgscore)
